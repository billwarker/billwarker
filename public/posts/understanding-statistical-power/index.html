<!DOCTYPE html>
<html lang="en">

<head>
    

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-174475056-1', 'auto');
	
	ga('send', 'pageview');
}
</script>



<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
<meta name="HandheldFriendly" content="True" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
<meta name="generator" content="Hugo 0.81.0" />


<link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/dsrkafuu/dsr-cdn@1/images/favicons/dsrca/favicon.ico" />



<title>Understanding Statistical Power - Data Science Notes</title>


<meta name="author" content="Will Barker" />


<meta name="description" content="A minimal Hugo theme with nice theme color." />


<meta name="keywords" content="stats" />

<meta property="og:title" content="Understanding Statistical Power" />
<meta property="og:description" content="Part 2 of 3 on a series of notes covering margin of error, power, and sample size calculations.
Notes, with questions and examples, taken from the following reading: https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Power/BS704_Power_print.html" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://billwarker.com/posts/understanding-statistical-power/" /><meta property="og:image" content="https://billwarker.com/img/og.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-11-22T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2020-11-22T00:00:00&#43;00:00" />


<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://billwarker.com/img/og.png"/>

<meta name="twitter:title" content="Understanding Statistical Power"/>
<meta name="twitter:description" content="Part 2 of 3 on a series of notes covering margin of error, power, and sample size calculations.
Notes, with questions and examples, taken from the following reading: https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Power/BS704_Power_print.html"/>




<link rel="stylesheet" href="/assets/css/fuji.min.css" />


<script async type="module" src="https://cdn.jsdelivr.net/npm/ionicons@5.0.1/dist/ionicons/ionicons.esm.js"></script>
<script async nomodule src="https://cdn.jsdelivr.net/npm/ionicons@5.0.1/dist/ionicons/ionicons.js"></script>



</head>

<body data-theme="auto">
    <script data-cfasync="false">
  
  var fujiThemeData = localStorage.getItem('fuji_data-theme');
  
  if (!fujiThemeData) {
    localStorage.setItem('fuji_data-theme', 'auto');
  } else {
    
    if (fujiThemeData !== 'auto') {
      document.body.setAttribute('data-theme', fujiThemeData === 'dark' ? 'dark' : 'light');
    }
  }
</script>
    <header>
    <div class="container-lg clearfix">
        <div class="col-12 header">
            <a class="title-main" href="https://billwarker.com">Data Science Notes</a>
            
            <span class="title-sub">Concepts and ideas learned throughout my studies</span>
            
        </div>
    </div>
</header>

    <main>
        <div class="container-lg clearfix">
            
            <div class="col-12 col-md-9 float-left content">
                
<article>
    
    <h2 class="post-item post-title">
        <a href="https://billwarker.com/posts/understanding-statistical-power/">Understanding Statistical Power</a>
    </h2>
    <div class="post-item post-meta">
        <span><i class="iconfont icon-today-sharp"></i>&nbsp;2020-11-22</span>



<span><i class="iconfont icon-pricetags-sharp"></i>&nbsp;<a href="/tags/stats">stats</a>&nbsp;</span>

    </div>
    
    <div class="post-content markdown-body">
        <p>Part 2 of 3 on a series of notes covering margin of error, power, and sample size calculations.</p>
<p>Notes, with questions and examples, taken from the following reading: <a href="https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Power/BS704_Power_print.html">https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Power/BS704_Power_print.html</a></p>
<h2 id="type-i-and-type-ii-errors-and-their-relationship-to-power">Type I and Type II Errors, and their relationship to Power</h2>
<p>In hypothesis testing there are two kinds of errors that can be made when deciding whether to reject the null hypothesis or not:</p>
<h3 id="type-i-error">Type I Error</h3>
<p>A type I error is falsely rejecting $h_0$ (the null hypothesis) when it is actually true, i.e. a false positive. Imagine a doctor looking at a man and telling him he&rsquo;s pregnant. The level of significance in a hypothesis test, $\alpha$ (alpha), is the probability of a type I error occuring:<br></p>
<p>$\alpha$ = P(Type I Error) = P(Rejct $H_0$ | $H_0$ is True)</p>
<p>We can use alpha as a control for the probability of making a type I error.</p>
<h3 id="type-ii-error">Type II Error</h3>
<p>A type II error is not rejecting $h_0$ when it it&rsquo;s actually false, i.e. a false negative. This time, the doctor looks at a pregnant lady and tells her she&rsquo;s got to start exercising to get rid of that giant bump in her belly. The probability of making a type II error is denoted as $\beta$ (beta):</p>
<p>$\beta$ = P(Type II Error) = P(Do not reject $H_0$ | $H_0$ is False)</p>
<h3 id="statistical-power">Statistical Power</h3>
<p>The power of a hypothesis test is the probability that $H_0$ will be correctly rejected when it is false. In other words, its the probability of detecting an effect if it actually exists. This is the probability of not making a type II error:</p>
<p>Power = 1 - $\beta$ = 1 - P(Do not reject $H_0$ | $H_0$ is False)</p>
<p>A good hypothesis tests has a low significance threshold (small $\alpha$) and high power (small $\beta$). Power is a single piece in a puzzle of four interconnected parts:</p>
<ul>
<li>The chosen significance level of the hyptothesis test, $\alpha$</li>
<li>The desired power of the test, (1 - $\beta$)</li>
<li>The sample size, which determines the variability of the parameter of interest</li>
<li>The effect size, the difference observed in the parameter of interest that denotes a meaningful difference (determined through domain knowledge)</li>
</ul>
<p>Power analysis involves estimating one of these variables given we know the values of the other three.</p>
<h2 id="example">Example</h2>
<p>Say we have some parameter of interest in a population that we want to make an inference on. We want to test the following hypothesis about this parameter:</p>
<p>The Null Hypothesis $H_0$: the population mean $\mu$ for the parameter is 90. $\mu$ = 90<br>
The Alternative Hypothesis $H_A$: the population mean $\mu$ for the parameter is not 90. $\mu$ $\neq$ 90</p>
<p>Here are the conditions for the test:</p>
<ul>
<li>We want to test a hypothesis with a significance level of $\alpha$ = 0.05, i.e. the probability of a false positive is only 5%.</li>
<li>The test is two sided, meaning we are testing to see if the parameter of interest is lower or higher than our null hypothesis</li>
<li>From previous tests on the population we can safely estimate that the standard deviation $\sigma$ of the parameter is 20. $\sigma$ = 20</li>
<li>To conduct this test we select a sample of n = 100</li>
</ul>
<p>To conduct the test we compute the parameter&rsquo;s sample mean $\bar{X}$ and then decide whether it provides enough evidence to support the alternative hypothesis. To do this we compute a test statistic and compare it to the appropriate critical value; since we know the variability of the parameter we can use a Z test.</p>
<p>If the null hypothesis is true ($\mu$ = 90) then we are likely to select a sample whose mean is close to 90. However it&rsquo;s possible to have a sample mean that is much larger or smaller than 90.</p>
<p>We can use the Central Limit Theorum here: when n is sufficiently large (in this case n=100 is enough), the distribution of sample means is approximately normal with a mean of:</p>
<p>$$ \mu_X = \mu $$</p>
<p>The standard error of our sample can be calculated as:</p>
<p>$$ SE = \frac{\sigma}{\sqrt{n}} = \frac{20}{\sqrt{100}} = 2.0 $$</p>
<p>If the null hypothesis is true, then it is possible to observe any sample mean from the sampling distribution below:</p>
<pre><code class="language-python">import numpy as np
from scipy.stats import norm
import matplotlib.pyplot as plt
</code></pre>
<pre><code class="language-python">h0_true_mean = 90
standard_deviation = 20
sample_size = 100
standard_error = standard_deviation / np.sqrt(sample_size)

h0_sample_dist = norm(h0_true_mean, standard_error)

x_range = h0_sample_dist.ppf(np.linspace(0.0001, 0.9999, num=1000))

plt.figure(figsize=(12,6))
plt.plot(x_range, h0_sample_dist.pdf(x_range))

plt.title(&quot;Sampling Distribution for $\\bar{X}$ given $H_0$: $\mu$ = 90 is True&quot;,
          fontsize=16, pad=10)
plt.xlabel(&quot;Values for $\\bar{X}$&quot;, fontsize=12)
plt.ylabel(&quot;$\\bar{X}$ Probability (PDF)&quot;, fontsize=12)

plt.show()
</code></pre>
<p><img class="img-zoomable" src="images/Understanding%20Statistical%20Power_3_0.png" alt="png" />
</p>
<p>Given this sampling distribution, we determine critical lower and upper values at which we reject $H_0$ based on our chosen significance ($\alpha = 0.05$) and the decision that this will be a two-sided test:</p>
<pre><code class="language-python">upper_rejection_cutoff = h0_sample_dist.ppf(0.975) # 2.5% probability of occuring at or after this threshold
lower_rejection_cutoff = h0_sample_dist.ppf(0.025) # 2.5% probability of occuring at or before this threshold

print(f&quot;Upper rejection cutoff: {upper_rejection_cutoff}&quot;)
print(f&quot;Lower rejection cutoff: {lower_rejection_cutoff}&quot;)
</code></pre>
<pre><code>Upper rejection cutoff: 93.9199279690801
Lower rejection cutoff: 86.0800720309199
</code></pre>
<p>Speaking in terms of the Z test, we would take the calculated sample mean $\bar{X}$ and convert it into a Z score. We&rsquo;d then find this Z score&rsquo;s probability on a standard normal distribution and if it was less than 5% (i.e. outside of our lower and upper rejection cutoffs), we would reject $H_0$.</p>
<p>In this example the critical values for a two-sided test with $\alpha$ = 0.05 are 86.06 and 93.92 (-1.96 and 1.96 on the Z scale), so the decision rule becomes reject $H_0$ if $\bar{X}$ $\leq$ 86.06 or if $\bar{X}$ $\geq$ 93.92.</p>
<pre><code class="language-python">plt.figure(figsize=(12,6))
plt.plot(x_range, h0_sample_dist.pdf(x_range))

plt.axvline(lower_rejection_cutoff, color='r', linestyle='--',
            label=f'{lower_rejection_cutoff}')
plt.axvline(upper_rejection_cutoff, color='r', linestyle='--',
            label=f'{upper_rejection_cutoff}')


lower_rejection_range = np.linspace(h0_sample_dist.ppf(0.0001),
                                    lower_rejection_cutoff,
                                    num=1000)

upper_rejection_range = np.linspace(upper_rejection_cutoff,
                                    h0_sample_dist.ppf(0.9999),
                                    num=1000)

non_rejection_range = np.linspace(lower_rejection_cutoff,
                                  upper_rejection_cutoff,
                                  num=1000)

plt.fill_between(non_rejection_range,
                 0,
                 h0_sample_dist.pdf(non_rejection_range),
                 color='green',
                 alpha=0.5)

plt.fill_between(lower_rejection_range,
                 0,
                 h0_sample_dist.pdf(lower_rejection_range),
                 color='red',
                 alpha=0.5)

plt.fill_between(upper_rejection_range,
                 0,
                 h0_sample_dist.pdf(upper_rejection_range),
                 color='red',
                 alpha=0.5)


plt.title(&quot;Rejection Region for Test $H_0$: $\\mu$ = 90 vs. $H_A$: $\\neq$ 90 at $\\alpha$ = 0.05&quot;,
          fontsize=16, pad=10)
plt.xlabel(&quot;Values for $\\bar{X}$&quot;, fontsize=12)
plt.ylabel(&quot;$\\bar{X}$ Probability (PDF)&quot;, fontsize=12)
plt.legend()

plt.show()
</code></pre>
<p><img class="img-zoomable" src="images/Understanding%20Statistical%20Power_7_0.png" alt="png" />
</p>
<p>The red areas that aren&rsquo;t between the two rejection lines represent the probability of a Type I error, which are the values for sample mean $\bar{X}$ whose probabilities sum to $\alpha$ = 0.05. If $\bar{X}$ is in these regions, we reject $H_0$ with a 5% probability of making a type I error. The green area represents the chosen range where $\bar{X}$ supports the null hypothesis, so we do not reject $h_0$.</p>
<p>If we suppose the alternative hypothesis, $H_A$ is true ($\mu$ $\neq$ 90) and that the true mean is actually 94, this is what the distributions of the sample mean look like for the null and alternate hypotheses:</p>
<pre><code class="language-python">true_mean = 94

x_range = np.linspace(80,100, num=1000)

hA_sample_dist = norm(true_mean, standard_error)

plt.figure(figsize=(12,6))

plt.axvline(true_mean, linestyle='--', label='$\mu$ = 94')
plt.axvline(lower_rejection_cutoff, color='r', linestyle='--',
            label=f'{lower_rejection_cutoff}')
plt.axvline(upper_rejection_cutoff, color='r', linestyle='--',
            label=f'{upper_rejection_cutoff}')

plt.plot(x_range, h0_sample_dist.pdf(x_range), color='b', label='$H_0$')
plt.plot(x_range, hA_sample_dist.pdf(x_range), color='r', label='$H_A$')

false_neg_range = np.linspace(lower_rejection_cutoff,
                              upper_rejection_cutoff, num=1000)
plt.fill_between(false_neg_range,
                 0,
                 hA_sample_dist.pdf(false_neg_range),
                 color='red',
                 alpha=0.5)

power_range = np.linspace(upper_rejection_cutoff,
                          100, num=1000)
plt.fill_between(power_range,
                 0,
                 hA_sample_dist.pdf(power_range),
                 color='green',
                 alpha=0.5)

plt.title(&quot;Distribution of $\\bar{X}$ under $H_0$: $\\mu$ = 90 and under $H_A$: $\\mu$ = 94 &quot;)
plt.xlabel(&quot;Values for $\\bar{X}$&quot;, fontsize=12)
plt.ylabel(&quot;$\\bar{X}$ Probability (PDF)&quot;, fontsize=12)
plt.legend()

plt.show()
</code></pre>
<p><img class="img-zoomable" src="images/Understanding%20Statistical%20Power_9_0.png" alt="png" />
</p>
<p>If the true mean is 94, then the alternative hypothesis $H_A$ is true. The probability of a type II error, $\beta$, is the red shaded area: this is the overlap between the alternate hypothesis' distribution has with the &ldquo;do not reject region&rdquo; of the null hypothesis.</p>
<p>The test&rsquo;s power, i.e. the probability of a true positive, rejecting $h_0$ when it is truly false, is the green shaded area to the right of the null hypothesis' upper rejection cutoff (as set by $\alpha$). It can be calculated as the probability of $\bar{X}$ being a value greater than $H_0$&rsquo;s upper rejection cutoff of 93.91, given $H_A$ is true (1 - probability of beta).</p>
<p>To do this we can put the upper rejection cutoff $\bar{X}$ = 93.91 in terms of its associated Z statistic:</p>
<p>$$ Power = 1 - \beta =  P(\bar{X} &gt; 93.91 | H_A) $$</p>
<p>$$ Power = P\left(Z &gt; \frac{93.92 - 94}{\frac{20}{\sqrt{100}}}\right) $$</p>
<p>$$ Power = P\left(Z &gt; -0.04\right) $$</p>
<p>We can convert the Z score of -0.04 using the cumulative density function, which will represent the probablility of drawing values less than or equal to -0.04 on a standard normal distribution</p>
<pre><code class="language-python">beta_calc = (upper_rejection_cutoff - true_mean)/standard_error
</code></pre>
<pre><code class="language-python">norm.cdf(beta_calc)
</code></pre>
<pre><code>0.4840322065576678
</code></pre>
<p>This gives us a beta $\beta$ of 0.484 (the probability of $\bar{X}$ being less or equal to 93.91, giving us a false negative). From there we can just subtract this value from 1 to get the probability of that not happening (true positive):</p>
<p>$$ Power = 1 - \beta = P(\bar{X} &gt; 93.91 | H_A) = 1 - 0.484 = 0.516 $$</p>
<p>Therefore, the given power of this test between $H_0$ and $H_A$ is 51.6% (not great). $\beta$ can also be calculated from our $H_A$ distribution object, by obtaining the CDF at $H_0$&rsquo;s upper rejection region:</p>
<pre><code class="language-python">beta_from_dist = hA_sample_dist.cdf(upper_rejection_cutoff)
power = round(1 - beta_from_dist, 4) * 100
print(f&quot;The power of this hypothesis test is {power}%&quot;)
</code></pre>
<pre><code>The power of this hypothesis test is 51.6%
</code></pre>
<p>$\beta$ and power are related to $\alpha$, the variance of the outcome and the effect size (i.e. the difference in the parameter of interest between $H_0$ and $H_A$). If we increased $\alpha$ from 0.05 to 0.10, the upper rejection limit of $H_0$ would shift to the left and be larger, increasing the test&rsquo;s power. While this would give the test higher power, it would also reduce the confidence we could have in the test.</p>
<p>The effect size and variance of the outcome affect power in clear ways:</p>
<ul>
<li>Increase the desired effect size between $H_0$ and $H_A$ to move their respective distributions further away from each other, reducing their overlap</li>
<li>Gathering more samples and reducing the variance of $H_0$ and $H_A$&rsquo;s distributions will also reduce their overlap</li>
</ul>
<p>Using the exact same components as the plot above, here is what the test&rsquo;s power becomes when $H_0$: $\mu$ = 90 and $H_A$: $\mu$ = 98, an effect size of 8 units:</p>
<pre><code class="language-python">hA_mean = 98

x_range = np.linspace(80,110, num=1000)

hA_sample_dist = norm(hA_mean, standard_error)

plt.figure(figsize=(12,6))

plt.axvline(lower_rejection_cutoff, color='r', linestyle='--',
            label=f'{lower_rejection_cutoff}')
plt.axvline(upper_rejection_cutoff, color='r', linestyle='--',
            label=f'{upper_rejection_cutoff}')

plt.plot(x_range, h0_sample_dist.pdf(x_range), color='b', label='$H_0$')
plt.plot(x_range, hA_sample_dist.pdf(x_range), color='r', label='$H_A$')

false_neg_range = np.linspace(lower_rejection_cutoff,
                              upper_rejection_cutoff, num=1000)
plt.fill_between(false_neg_range,
                 0,
                 hA_sample_dist.pdf(false_neg_range),
                 color='blue',
                 alpha=0.5)

power_range = np.linspace(upper_rejection_cutoff,
                          110, num=1000)
plt.fill_between(power_range,
                 0,
                 hA_sample_dist.pdf(power_range),
                 color='green',
                 alpha=0.5)

plt.title(&quot;Distribution of $\\bar{X}$ under $H_0$: $\\mu$ = 90 and under $H_A$: $\\mu$ = 94 &quot;)
plt.xlabel(&quot;Values for $\\bar{X}$&quot;, fontsize=12)
plt.ylabel(&quot;$\\bar{X}$ Probability (PDF)&quot;, fontsize=12)
plt.legend()
</code></pre>
<pre><code>&lt;matplotlib.legend.Legend at 0x7ff6971a7390&gt;
</code></pre>
<p><img class="img-zoomable" src="images/Understanding%20Statistical%20Power_19_1.png" alt="png" />
</p>
<p>Calculating the Power for this test by obtaining $\beta$ from $H_A$&rsquo;s distribution variable:</p>
<pre><code class="language-python">beta_from_dist = hA_sample_dist.cdf(upper_rejection_cutoff)
power = round(1 - beta_from_dist, 4) * 100
print(f&quot;The power of this hypothesis test is {power}%&quot;)
</code></pre>
<pre><code>The power of this hypothesis test is 97.92999999999999%
</code></pre>
<h3 id="note-to-be-continued-in-part-3-ensuring-a-test-has-high-power">Note to be continued in Part 3: Ensuring a Test has High Power</h3>
    </div>
</article>




            </div>
            <aside class="col-12 col-md-3 float-left sidebar">
    
    <div class="sidebar-item sidebar-pages">
        <h3>Pages</h3>
        <ul>
            
            <li>
                <a href="/">Home</a>
            </li>
            
            <li>
                <a href="/archives/">Archives</a>
            </li>
            
            <li>
                <a href="/about/">About</a>
            </li>
            
            <li>
                <a href="/search/">Search</a>
            </li>
            
            <li>
                <a href="/index.xml">RSS</a>
            </li>
            
        </ul>
    </div>
    
    <div class="sidebar-item sidebar-links">
        <h3>Links</h3>
        <ul>
            
            <li>
                <a href="https://github.com/billwarker" target="_blank"><span>GitHub</span></a>
            </li>
            
        </ul>
    </div>
    
    <div class="sidebar-item sidebar-tags">
        <h3>Tags</h3>
        <div>
            
            <span>
                <a href="/tags/analytics/">analytics</a>
            </span>
            
            <span>
                <a href="/tags/causal-inference/">causal-inference</a>
            </span>
            
            <span>
                <a href="/tags/comp-sci/">comp-sci</a>
            </span>
            
            <span>
                <a href="/tags/experimentation/">experimentation</a>
            </span>
            
            <span>
                <a href="/tags/handson-ml/">handson-ml</a>
            </span>
            
            <span>
                <a href="/tags/ml/">ml</a>
            </span>
            
            <span>
                <a href="/tags/stats/">stats</a>
            </span>
            
            <span>
                <a href="/tags/strategy/">strategy</a>
            </span>
            
        </div>
    </div>
    
</aside>
        </div>
        <div class="btn">
    <div class="btn-menu" id="btn-menu">
        <i class="iconfont icon-grid-sharp"></i>
    </div>
    <div class="btn-toggle-mode">
        <i class="iconfont icon-contrast-sharp"></i>
    </div>
    <div class="btn-scroll-top">
        <i class="iconfont icon-chevron-up-circle-sharp"></i>
    </div>
</div>
<aside class="sidebar-mobile" style="display: none;">
  <div class="sidebar-wrapper">
    
    <div class="sidebar-item sidebar-pages">
        <h3>Pages</h3>
        <ul>
            
            <li>
                <a href="/">Home</a>
            </li>
            
            <li>
                <a href="/archives/">Archives</a>
            </li>
            
            <li>
                <a href="/about/">About</a>
            </li>
            
            <li>
                <a href="/search/">Search</a>
            </li>
            
            <li>
                <a href="/index.xml">RSS</a>
            </li>
            
        </ul>
    </div>
    
    <div class="sidebar-item sidebar-links">
        <h3>Links</h3>
        <ul>
            
            <li>
                <a href="https://github.com/billwarker" target="_blank"><span>GitHub</span></a>
            </li>
            
        </ul>
    </div>
    
    <div class="sidebar-item sidebar-tags">
        <h3>Tags</h3>
        <div>
            
            <span>
                <a href="/tags/analytics/">analytics</a>
            </span>
            
            <span>
                <a href="/tags/causal-inference/">causal-inference</a>
            </span>
            
            <span>
                <a href="/tags/comp-sci/">comp-sci</a>
            </span>
            
            <span>
                <a href="/tags/experimentation/">experimentation</a>
            </span>
            
            <span>
                <a href="/tags/handson-ml/">handson-ml</a>
            </span>
            
            <span>
                <a href="/tags/ml/">ml</a>
            </span>
            
            <span>
                <a href="/tags/stats/">stats</a>
            </span>
            
            <span>
                <a href="/tags/strategy/">strategy</a>
            </span>
            
        </div>
    </div>
    
    
    
    
  </div>
</aside>
    </main>

    <footer>
    <div class="container-lg clearfix">
        <div class="col-12 footer">
            <span>&copy; 2021 <a href="https://billwarker.com">Will Barker</a>
        </div>
    </div>
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
    onload='renderMathInElement(document.body,
    {
              delimiters: [
                  {left: "$$", right: "$$", display: true},
                  {left: "$", right: "$", display: false},
              ]
          }
      );'>
</script>
    
</footer>
    
<script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.0/lazysizes.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/prismjs@1.23.0/components/prism-core.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/prismjs@1.23.0/plugins/autoloader/prism-autoloader.min.js"></script>



<script defer src="/assets/js/fuji.min.js"></script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
    onload='renderMathInElement(document.body,
    {
              delimiters: [
                  {left: "$$", right: "$$", display: true},
                  {left: "$", right: "$", display: false},
              ]
          }
      );'>
</script>


</body>

</html>